Abstract:
The idea of the project is to help detect audience engagement by identifying the audience's mood by capturing their face. This could enable the speaker to get real-time feedback on people's reaction. This can also be extended to let the speaker know the speaker’s impact on the audience, say how many people feel happy after narrating a feel-good story. Especially in a virtual setting, a speaker might be lacking such feedback and that could help the speaker to dynamically adjust to increase the audience's engagement and give a better overall experience to the listeners. In order to achieve this, we will be relying heavily on the paper, “Facial Expression Recognition in the Wild via Deep Attentive Center Loss” which is a recent and highly accurate way for Facial Expression Recognition (FER) and has been proved to work on varied emotion datasets such as RAF-DB and AffectNet. This paper brings in Deep Attentive Center Loss (DACL) method, which helps in tackling the FER problem better than old methods.
